{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **Retrieve and Generate (RAG)**\n",
    "\n",
    "Until now, we’ve been querying LLMs hosted on AWS Bedrock purely based on the model’s pretraining, which relies on large-scale internet data. While powerful, these models are not well-suited for answering questions about internal or domain-specific resources. In such cases, they often produce inaccurate or \"hallucinated\" responses, as they generate answers based solely on statistical probability rather than grounded knowledge.\n",
    "\n",
    "To address this limitation, we use a technique called **Retrieval-Augmented Generation (RAG)**.\n",
    "\n",
    "---\n",
    "\n",
    "### **What is RAG?**\n",
    "\n",
    "RAG enhances LLM performance by augmenting model inputs with relevant data retrieved from a custom knowledge base. Here's how it works:\n",
    "\n",
    "1. **Data Preparation**: Internal documents or resources are parsed and converted into **embedding vectors**, which are then stored in a **vector database**.\n",
    "2. **Query Handling**: When a user asks a question, the query is also converted into an embedding. A similarity search (commonly cosine similarity) is performed against the stored vectors to find the most relevant content.\n",
    "3. **Response Generation**: The matched content is then transformed back into text and included in the prompt sent to the LLM. This gives the model context-specific knowledge to generate accurate, grounded responses.\n",
    "\n",
    "Thanks to RAG, the model can now respond based on both its pre-trained knowledge and your internal data.\n",
    "\n",
    "---\n",
    "\n",
    "### **Two Key Phases of RAG**\n",
    "\n",
    "1. **Indexing** *(Offline Process)*\n",
    "\n",
    "   * Parse internal documents\n",
    "   * Generate embeddings\n",
    "   * Store embeddings in a vector store\n",
    "\n",
    "2. **Retrieval and Generation** *(Runtime)*\n",
    "\n",
    "   * Convert user query into an embedding\n",
    "   * Find the closest matches in the vector store\n",
    "   * Retrieve and format the matched content\n",
    "   * Combine it with the user’s query and send it to the LLM\n",
    "\n",
    "---\n",
    "\n",
    "We’ll explore the implementation of RAG in more detail in the next sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-text-splitters in /opt/miniconda3/lib/python3.13/site-packages (0.3.8)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.26-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: langgraph in /opt/miniconda3/lib/python3.13/site-packages (0.4.10)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /opt/miniconda3/lib/python3.13/site-packages (from langchain-text-splitters) (0.3.66)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /opt/miniconda3/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (0.4.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/miniconda3/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/miniconda3/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/miniconda3/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/miniconda3/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/miniconda3/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (4.12.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /opt/miniconda3/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (2.10.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/miniconda3/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (2.1)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /opt/miniconda3/lib/python3.13/site-packages (from langchain-community) (0.3.26)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/miniconda3/lib/python3.13/site-packages (from langchain-community) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/miniconda3/lib/python3.13/site-packages (from langchain-community) (2.32.3)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Downloading aiohttp-3.12.13-cp313-cp313-macosx_11_0_arm64.whl.metadata (7.6 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: numpy>=2.1.0 in /opt/miniconda3/lib/python3.13/site-packages (from langchain-community) (2.3.1)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading frozenlist-1.7.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading multidict-6.5.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading propcache-0.3.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading yarl-1.20.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (73 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/miniconda3/lib/python3.13/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/miniconda3/lib/python3.13/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (2.27.1)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.13/site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.13/site-packages (from requests<3,>=2->langchain-community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.13/site-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.13/site-packages (from requests<3,>=2->langchain-community) (2025.6.15)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: langgraph-checkpoint>=2.0.26 in /opt/miniconda3/lib/python3.13/site-packages (from langgraph) (2.1.0)\n",
      "Requirement already satisfied: langgraph-prebuilt>=0.2.0 in /opt/miniconda3/lib/python3.13/site-packages (from langgraph) (0.2.3)\n",
      "Requirement already satisfied: langgraph-sdk>=0.1.42 in /opt/miniconda3/lib/python3.13/site-packages (from langgraph) (0.1.70)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /opt/miniconda3/lib/python3.13/site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /opt/miniconda3/lib/python3.13/site-packages (from langgraph-checkpoint>=2.0.26->langgraph) (1.10.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /opt/miniconda3/lib/python3.13/site-packages (from langgraph-sdk>=0.1.42->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /opt/miniconda3/lib/python3.13/site-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.18)\n",
      "Requirement already satisfied: anyio in /opt/miniconda3/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/miniconda3/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/miniconda3/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (0.16.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/miniconda3/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/miniconda3/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (0.23.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/miniconda3/lib/python3.13/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.3.1)\n",
      "Downloading langchain_community-0.3.26-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.12.13-cp313-cp313-macosx_11_0_arm64.whl (464 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.5.1-cp313-cp313-macosx_11_0_arm64.whl (42 kB)\n",
      "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.20.1-cp313-cp313-macosx_11_0_arm64.whl (88 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.7.0-cp313-cp313-macosx_11_0_arm64.whl (45 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading propcache-0.3.2-cp313-cp313-macosx_11_0_arm64.whl (41 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-inspection, python-dotenv, propcache, mypy-extensions, multidict, marshmallow, httpx-sse, frozenlist, attrs, aiohappyeyeballs, yarl, typing-inspect, aiosignal, pydantic-settings, dataclasses-json, aiohttp, langchain-community\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/17\u001b[0m [langchain-community]ngchain-community]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.13 aiosignal-1.3.2 attrs-25.3.0 dataclasses-json-0.6.7 frozenlist-1.7.0 httpx-sse-0.4.1 langchain-community-0.3.26 marshmallow-3.26.1 multidict-6.5.1 mypy-extensions-1.1.0 propcache-0.3.2 pydantic-settings-2.10.1 python-dotenv-1.1.1 typing-inspect-0.9.0 typing-inspection-0.4.1 yarl-1.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-text-splitters langchain-community langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU \"langchain[aws]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "model  = init_chat_model(\"anthropic.claude-3-5-sonnet-20240620-v1:0\", model_provider=\"bedrock_converse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Indexing**\n",
    "\n",
    "To begin the indexing process, we use **document loaders** to load content from various sources. LangChain provides support for multiple data types, including:\n",
    "\n",
    "* Web pages\n",
    "* PDF files\n",
    "* Plain text documents\n",
    "* and more\n",
    "\n",
    "These loaders help standardize and prepare the data for further processing and embedding.\n",
    "\n",
    "📖 **Reference:**\n",
    "[LangChain Document Loaders](https://python.langchain.com/docs/concepts/document_loaders/)\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-05-30T10:02:58-04:00', 'author': 'Resendiz, Elvia', 'moddate': '2025-05-30T10:02:58-04:00', 'source': './EVL.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}\n",
      "\n",
      "840\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "# Filter to fetch the only required content from the document\n",
    "# In this case only html tags with below values are only loaded\n",
    "# bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-content\", \"post-header\"))\n",
    "# loader = WebBaseLoader(\n",
    "#   web_paths = (\"https://lilianweng.github.io/posts/2023-06-23-agent/\"),\n",
    "#   bs_kwargs={\"parse_only\": bs4_strainer},\n",
    "# )\n",
    "# docs = loader.load()\n",
    "\n",
    "filePath = \"<sample pdf file>\"\n",
    "loader = PyPDFLoader(filePath)\n",
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "  pages.append(page)\n",
    "\n",
    "\n",
    "print(f\"{pages[0].metadata}\\n\")\n",
    "print(len(pages[0].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import BedrockEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "embeddings = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v2:0\")\n",
    "vector_store = InMemoryVectorStore.from_documents(pages, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSample code to search the vector store\\n\\ndocs = vector_store.similarity_search(\"<query>\", k=2)\\nfor doc in docs:\\n  print(f\"Metadata: {doc.metadata[\"page\"]}\")\\n  print(f\"Content: {doc.page_content}\\n\")\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Sample code to search the vector store\n",
    "\n",
    "docs = vector_store.similarity_search(\"<query>\", k=2)\n",
    "for doc in docs:\n",
    "  print(f\"Metadata: {doc.metadata[\"page\"]}\")\n",
    "  print(f\"Content: {doc.page_content}\\n\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "Now that our vector store is loaded with documents, it’s time to add the **Retrieve** and **Generate** nodes to the graph. This process is similar to setting up a chatbot.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "* Create nodes for **Retrieve** and **Generate**.\n",
    "\n",
    "* Connect edges between **Start → Retrieve** and **Retrieve → Generate**.\n",
    "\n",
    "* The **Retrieve** node performs a search on the vector store using the user’s question.\n",
    "\n",
    "* The **Generate** node formats the prompt by combining the user’s question with the retrieved context, then invokes the model with this prompt to produce the response.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "Let’s begin by designing the prompt template. We can create a custom prompt using LangChain’s prompt template library. For this example, we’ll use a RAG-specific template that has been shared on the LangChain Hub.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.13/site-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain import hub\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "example_messages = prompt.invoke(\n",
    "  {\"context\": \"(context goes here)\", \"question\": \"Question goes here\"}\n",
    ").to_messages()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['content', 'question'], input_types={}, partial_variables={}, messages=[AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an AI assistant that helps users find information in a document. You are given a context and a question. Your task is to provide a concise answer based on the context.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['content', 'question'], input_types={}, partial_variables={}, template='For the following question: {question}, give me the consice answer from this content: {content}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "example_messages = [\n",
    "  { \"role\": \"assistant\", \"content\": \"You are an AI assistant that helps users find information in a document. You are given a context and a question. Your task is to provide a concise answer based on the context.\" },\n",
    "  { \"role\": \"user\", \"content\": \"For the following question: {question}, give me the consice answer from this content: {content}\" }\n",
    "]\n",
    "prompt_template = ChatPromptTemplate.from_messages(example_messages)\n",
    "prompt_template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "# defining the state for the rag, keeping track of the question, context, and answer\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    content: List[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating retreive and generate graph nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retreive(state: State):\n",
    "  retrieved_docs = vector_store.similarity_search(state[\"question\"], k=2)\n",
    "  return { \"content\": retrieved_docs }\n",
    "\n",
    "def generate(state: State):\n",
    "  content = \"\\n\\n\".join(doc.page_content for doc in state[\"content\"])\n",
    "  prompt = prompt_template.invoke({\"question\": state[\"question\"], \"content\": content})\n",
    "  responses = model.invoke(prompt)\n",
    "  return { \"answer\": responses.content }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "graph_builder = StateGraph(State).add_sequence([ retreive, generate ])\n",
    "graph_builder.add_edge(START, \"retreive\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Answer: Based on the given content, the position of Dinesh Reddy Allam at '\n",
      " 'Purpose Financial is Sr. Software Engineer.\\n'\n",
      " '\\n')\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "result = graph.invoke({\"question\": \"What is the position of the Dinesh Reddy Allam im purpose financial?\"})\n",
    "# pprint.pprint(f'Content: {result[\"content\"]}\\n\\n')\n",
    "pprint.pprint(f'Answer: {result[\"answer\"]}\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Further Improvements / Use Cases: Enhancing Query Analysis\n",
    "\n",
    "At a high level, we can introduce an additional step called **query analysis**. In this step, we analyze the user’s query using a model designed to produce structured output. Based on this structured output, we can perform a more targeted search in the vector store to retrieve more relevant documents.\n",
    "\n",
    "**Example:**\n",
    "When indexing documents into the vector store, we can enrich their metadata—for instance, by adding sentiment labels (positive, negative) during the data preparation phase. Then, as part of the initial stage in the processing graph, we can analyze the query’s sentiment using a structured-output model. This sentiment information is passed to the retrieve node, allowing it to refine the similarity search by also filtering based on the sentiment metadata.\n",
    "\n",
    "The retrieved documents, now more closely aligned with the query’s intent, are then passed to the generate node for a more accurate and precise response.\n",
    "\n",
    "---\n",
    "\n",
    "**This query analysis step significantly improves the relevance of documents retrieved from the vector store.**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s a simple example in Python using **LangChain** and **Pydantic** to create a query analysis model that outputs structured data (like sentiment), which can then be used to guide retrieval from a vector store.\n",
    "\n",
    "---\n",
    "\n",
    "### Sample Code: Query Analysis Model with Structured Output\n",
    "\n",
    "```python\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "import json\n",
    "\n",
    "# 1. Define a Pydantic model for the structured output\n",
    "class QueryAnalysisResult(BaseModel):\n",
    "    sentiment: Literal[\"positive\", \"neutral\", \"negative\"] = Field(..., description=\"Sentiment of the query\")\n",
    "    intent: str = Field(..., description=\"User intent extracted from query\")\n",
    "\n",
    "# 2. Create an output parser to parse the JSON response into the Pydantic model\n",
    "class QueryAnalysisOutputParser(BaseOutputParser):\n",
    "    def parse(self, text: str) -> QueryAnalysisResult:\n",
    "        data = json.loads(text)\n",
    "        return QueryAnalysisResult(**data)\n",
    "\n",
    "# 3. Define the prompt template to instruct the LLM to output structured JSON\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "        \"Analyze the user's query and provide the sentiment (positive, neutral, negative) and user intent in JSON format.\"\n",
    "    ),\n",
    "    HumanMessagePromptTemplate.from_template(\"{query}\")\n",
    "])\n",
    "\n",
    "# 4. Initialize the chat model (using OpenAI GPT for example)\n",
    "chat_model = ChatOpenAI(temperature=0)\n",
    "\n",
    "# 5. Define a function to perform query analysis\n",
    "def analyze_query(query: str) -> QueryAnalysisResult:\n",
    "    # Format the prompt with the user query\n",
    "    messages = prompt_template.format_messages(query=query)\n",
    "    # Get the LLM response\n",
    "    response = chat_model(messages)\n",
    "    # Parse the JSON output into the structured model\n",
    "    parsed_output = QueryAnalysisOutputParser().parse(response.content)\n",
    "    return parsed_output\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    user_query = \"I am unhappy with the recent service update.\"\n",
    "    analysis = analyze_query(user_query)\n",
    "    print(f\"Sentiment: {analysis.sentiment}\")\n",
    "    print(f\"Intent: {analysis.intent}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "* **Step 1:** Defines a Pydantic model `QueryAnalysisResult` with fields for sentiment and intent.\n",
    "* **Step 2:** Implements a custom parser that converts the model’s JSON output into the Pydantic model.\n",
    "* **Step 3:** Creates a prompt template that instructs the LLM to respond with a JSON containing sentiment and intent.\n",
    "* **Step 4:** Sets up a chat model (you can replace this with any supported LLM).\n",
    "* **Step 5:** Runs the query through the model and parses the structured output.\n",
    "\n",
    "---\n",
    "\n",
    "You can then use the sentiment and intent fields in your retrieval node to filter or enhance the vector store search.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
